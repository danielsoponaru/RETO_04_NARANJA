datos=datos[,-1]
datos<-datos %>% mutate(minutos=(timestop-timestart))
sumas<-datos %>% group_by(UserID,streamername ) %>%
summarise(totalminutos=sum(minutos))
datos<- pivot_wider(sumas, names_from = streamername, values_from = totalminutos)
View(datos)
datos<- datos[,-1]
matriz<- as.matrix(datos)
View(matriz)
##########
# 2
datos=read_xlsx("C:/Users/jonba/Downloads/SmallSmall.xlsx")
datos=datos[,-1]
View(datos)
datos=mutate(fill=datos$timestop-datos$timestart)
str(datos)
datos=datos%>%mutate(fill=datos$timestop-datos$timestart)
View(datos)
datos=datos%>%mutate(rating=datos$timestop-datos$timestart)
matriz <- datos %>%
select(UserID, streamID, rating) %>%
pivot_wider(names_from = streamID, values_from = rating)
View(matriz)
matriz <- matriz[, -1]
View(matriz)
matriz <- datos %>%
select(UserID, streamID, rating) %>%
pivot_wider(names_from = streamID, values_from = rating)
View(matriz)
matriz <- matriz[, -1]
matriz <- datos %>%
select(UserID, streamID, rating) %>%
pivot_wider(names_from = streamID, values_from = rating)
View(matriz)
matriz <- matriz[, -1]
rownames(matriz) <- unique(datos$UserID)
a=data.frame(ID=c(241,222,276,273,200,229,231,239,286),
user=c("u1","u1","u2","u2","u3","u3","u3","u4","u4"),
item=c("m1","m3","m1","m2","m1","m2","m3","m2","m3"),
rating=c(2,3,5,2,3,3,1,2,2)
)
b <- a %>%
select(user, item, rating) %>%
pivot_wider(names_from = item, values_from = rating)
b <- b[, -1]
View(b)
rownames(matriz) <- unique(datos$UserID)
View(matriz)
rating_matrix <- as.matrix(matriz)
rrm <- as(rating_matrix, "realRatingMatrix")
rating_matrix2 <- as.matrix(matriz)
realratingmatrix <- as(rating_matrix, "realRatingMatrix")
realratingmatrix <- as(rating_matrix2, "realRatingMatrix")
e<- evaluationScheme(data = realratingmatrix, method = "split", train = 0.8,
given = 1, goodRating = 5)
View(e)
pred_pop<-calcPredictionAccuracy(prediccionesp, getData(e, "unknown"),given = 1, goodRating = 4)
popular<-Recommender(getData(e, "train"), "Popular")
prediccionesp<-predict(popular, getData(e, "known"), type="topNList")
as(prediccionesp, "list")
pred_pop<-calcPredictionAccuracy(prediccionesp, getData(e, "unknown"),given = 1, goodRating = 4)
#POPULAR
popular<-Recommender(getData(e, "train"), "Popular")
prediccionesp<-predict(popular, getData(e, "known"), type="topNList")
as(prediccionesp, "list")
pred_pop<-calcPredictionAccuracy(prediccionesp, getData(e, "unknown"),given = 1, goodRating = 4)
#UBCF
ubcf<-Recommender(getData(e, "train"), "UBCF")
prediccionesu<-predict(ubcf, getData(e, "known"), type="topNList")
as(prediccionesu, "list")
pred_ubcf<-calcPredictionAccuracy(prediccionesu, getData(e, "unknown"),given = 1, goodRating = 4)
#IBCF
ibcf<-Recommender(getData(e, "train"), "IBCF")
#POPULAR
popular<-Recommender(getData(e, "train"), "Popular")
prediccionesp<-predict(popular, getData(e, "known"), type="topNList")
as(prediccionesp, "list")
pred_pop<-calcPredictionAccuracy(prediccionesp, getData(e, "unknown"),given = 1, goodRating = 4)
#UBCF
ubcf<-Recommender(getData(e, "train"), "UBCF")
prediccionesu<-predict(ubcf, getData(e, "known"), type="topNList")
as(prediccionesu, "list")
pred_ubcf<-calcPredictionAccuracy(prediccionesu, getData(e, "unknown"),given = 1, goodRating = 4)
#IBCF
ibcf<-Recommender(getData(e, "train"), "IBCF")
#random
random<-Recommender(getData(e, "train"), "Random")
prediccionesr<-predict(random, getData(e, "known"), type="topNList")
as(prediccionesr, "list")
pred_random<-calcPredictionAccuracy(prediccionesr, getData(e, "unknown"),given = 1, goodRating = 4)
#SVD
SVD<-Recommender(getData(e, "train"), "SVD")
prediccionesvd<-predict(SVD, getData(e, "known"), type="topNList")
as(prediccionesvd, "list")
pred_svd<-calcPredictionAccuracy(prediccionesvd, getData(e, "unknown"),given = 1, goodRating = 4)
resultados<-as.data.frame(rbind(pred_pop,pred_random,pred_svd, pred_ibcf, pred_ubcf))
resultados<-as.data.frame(rbind(pred_pop,pred_random,pred_svd, pred_ubcf))
resultados$accuracy <- (resultados$TP + resultados$TN) / resultados$N
resultados
#IBCF
ibcf<-Recommender(getData(e, "train"), "IBCF")
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv")
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv")
centroides=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv")
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv")
centroides=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv")
View(centroides)
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv", sep=";")
centroides=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv", sep=";")
View(centroides)
View(df)
j=as.data.frame(scale(df))
distancia <- dist(j, method = "euclidean")
hc <- hclust(distancia, method = "ward.D2")
clusters_jerarquico <- cutree(hc, k = 4)
j$cluster <- as.factor(clusters_jerarquico)
pca_result <- prcomp(j)
str(j)
pca_result <- prcomp(j)
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv", sep=";")
centroides=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv", sep=";")
j=as.data.frame(scale(df))
View(j)
distancia <- dist(j, method = "euclidean")
hc <- hclust(distancia, method = "ward.D2")
clusters_jerarquico <- cutree(hc, k = 4)
j$cluster <- as.factor(clusters_jerarquico)
str(j)
pca_result <- prcomp(j)
df$cluster <- as.factor(clusters_jerarquico)
str(j)
pca_result <- prcomp(j)
j=as.data.frame(scale(df))
j=as.data.frame(scale(df))
distancia <- dist(j, method = "euclidean")
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv", sep=";")
centroides=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv", sep=";")
j=as.data.frame(scale(df))
distancia <- dist(j, method = "euclidean")
hc <- hclust(distancia, method = "ward.D2")
clusters_jerarquico <- cutree(hc, k = 4)
df$cluster <- as.factor(clusters_jerarquico)
View(j)
View(df)
View(j)
str(j)
j=as.data.frame(scale(df))
j=as.data.frame(scale(df))
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv", sep=";")
centroides=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv", sep=";")
j=as.data.frame(scale(df))
distancia <- dist(j, method = "euclidean")
hc <- hclust(distancia, method = "ward.D2")
clusters_jerarquico <- cutree(hc, k = 4)
df$cluster <- as.factor(clusters_jerarquico)
str(j)
pca_result <- prcomp(j)
pca_df <- data.frame(pca_result$x, cluster = j$cluster)
pca_df <- data.frame(pca_result$x, cluster = df$cluster)
pca_distancia =data.frame(pca_result$x, cluster = df$cluster)
centroides_distancia <- pca_distancia %>%
group_by(cluster) %>%
summarise_all(mean)
centroides <- pca_df %>%
group_by(cluster) %>%
summarise(PC1 = mean(PC1), PC2 = mean(PC2))
intercluster=sum(dist(centroides_distancia))
intracluster <- sum(sqrt(rowSums((as.matrix(pca_distancia[, 1:2]) -
as.matrix(centroides_distancia[match(pca_distancia$cluster, centroides_distancia$cluster), 2:3]))^2)))
cat("Distancia Intercluster:", intercluster, "  |  Distancia Intracluster:", intracluster, "\n")
View(centroides)
cen=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv", sep=";")
View(cen)
clusters_jerarquico <- cutree(hc, k = 20)
df$cluster <- as.factor(clusters_jerarquico)
str(j)
pca_result <- prcomp(j)
pca_df <- data.frame(pca_result$x, cluster = df$cluster)
pca_distancia =data.frame(pca_result$x, cluster = df$cluster)
centroides_distancia <- pca_distancia %>%
group_by(cluster) %>%
summarise_all(mean)
centroides <- pca_df %>%
group_by(cluster) %>%
summarise(PC1 = mean(PC1), PC2 = mean(PC2))
intercluster=sum(dist(centroides_distancia))
intracluster <- sum(sqrt(rowSums((as.matrix(pca_distancia[, 1:2]) -
as.matrix(centroides_distancia[match(pca_distancia$cluster, centroides_distancia$cluster), 2:3]))^2)))
cat("Distancia Intercluster:", intercluster, "  |  Distancia Intracluster:", intracluster, "\n")
kmeans<-kmeans(datos, centers = 20)
cen_k<-as.data.frame(kmeans$centers)
cen_k<- cen_k %>% arrange(desc(V1))
j=as.data.frame(scale(df))
kmeans<-kmeans(df, centers = 20)
cen_k<-as.data.frame(kmeans$centers)
cen_k<- cen_k %>% arrange(desc(V1))
View(cen)
########
# 3
df=read.csv("C:/Users/jonba/Downloads/a1datos.csv", sep=";", header=F)
cen=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv", sep=";", header=F)
reales=read.csv("C:/Users/jonba/Downloads/a1-centroides.csv", sep=";", header=F)
kmeans<-kmeans(df, centers = 20)
cen_k<-as.data.frame(kmeans$centers)
cen_k<- cen_k %>% arrange(desc(V1))
D1 <- dist(df, method = "euclidean")
D2 <- hclust(D1, method = "ward.D")
# la ariketa nos dice que k=20
D3 <- cutree(D2, k = 20)
D4 <- mutate(df, cluster = D3)
cen_j <- D4 %>%
group_by(cluster) %>%
summarise_all(list(mean)) %>%
mutate(cluster = as.factor(as.character(cluster)))
cen_j<-cen_j[,-1]
cen_j<- cen_j %>% arrange(desc(V1))
j<-dist(cen_j, reales)
k<-dist(cen_k, reales)
which.min(c(sum(j), sum(k)))
j<-dist(cen_j, reales)
k<-dist(cen_k, reales)
which.min(c(sum(j), sum(k)))
j
a=read.csv("C:/Users/jonba/Downloads/ratingv2 (1).csv")
a=read.csv("C:/Users/jonba/Downloads/ratingv2 (1).csv", sep=";")
a=read.csv("C:/Users/jonba/Downloads/ratingv2 (1).csv", sep=";")
View(a)
a[,-4]
a=a[,-4]
View(a)
df <- data.frame(
Record_Number = c("R1", "R2", "R3", "R4", "R5", "R6", "R7"),
A = c(1.0, 1.5, 3.0, 5.0, 3.5, 4.5, 3.5),
B = c(1.0, 2.0, 4.0, 7.0, 5.0, 5.0, 4.5)
)
df <- data.frame(
Record_Number = c("R1", "R2", "R3", "R4", "R5", "R6", "R7"),
A = c(1.0, 1.5, 3.0, 5.0, 3.5, 4.5, 3.5),
B = c(1.0, 2.0, 4.0, 7.0, 5.0, 5.0, 4.5)
)
C1=c(1,1)
C2=c(5,7)
kmeans<-kmeans(df, centers = 2)
kmeans<-kmeans(df, centers = C1,C2)
kmeans<-kmeans(df, centers = c(C1,C2))
centroides_iniciales <- matrix(c(1, 1,
5, 7),
nrow = 2, byrow = TRUE)
a=read.csv("C:/Users/jonba/Downloads/ratingv2 (1).csv", sep=";")
kmeans<-df%>%
select(A,B)%>%
kmeans(df, centers =centroides_iniciales)
library(dplyr)
kmeans<-df%>%
select(A,B)%>%
kmeans(df, centers =centroides_iniciales)
kmeans<-df%>%
select(A,B)%>%
kmeans(centers =centroides_iniciales)
df$cluster <- resultado_kmeans$cluster
df$cluster <- kmeans$cluster
View(kmeans)
View(df)
kmeans$centers
kmeans$cluster
kmeans<-df%>%
select(A,B)%>%
kmeans(centers =3)
df$cluster <- kmeans$cluster
View(df)
kmeans<-df%>%
select(A,B)%>%
kmeans(centers =centroides_iniciales)
df$cluster <- kmeans$cluster
kmeans$centers
########
# 1
wars=read.csv("C:/Users/jonba/Downloads/death_star_polution.csv")
########
# 1
wars=read.csv("C:/Users/jonba/Downloads/death_star_polution.csv")
View(wars)
View(wars)
View(wars)
wars$imperial_pollution=wars%>%ifelse(wars$imperial_pollution>4,1,0)
?ifelse
wars$imperial_pollution=wars%>%ifelse(wars$imperial_pollution>4,1,0)
wars$imperial_pollution=wars%>%ifelse(wars$imperial_pollution>=4,1,0)
wars$imperial_pollution=wars%>%ifelse(wars$imperial_pollution>=4 ,1,0)
wars$imperial_pollution=ifelse(wars$imperial_pollution>=4 ,1,0)
View(wars)
# Cargar librerías necesarias
library(recommenderlab)
library(rsparse)
library(Matrix)
library(dplyr)
# 1. Cargar datos
data <- readRDS("matriz.RDS")
objetivos <- readRDS("objetivos.RDS")
clientes_objetivo <- objetivos$objetivo2$obj
productos <- readRDS("maestroestr.RDS")
#  Vector con los códigos de los 20 productos en oferta (reemplaza con los reales si hace falta)
productos_en_oferta <- c("X12650103", "X01027405", "X05030101", "X05030102", "X01012310",
"X11040303", "X08230125", "X01201505", "X05040180", "X01201005", "X09070103",
"X04200505", "X01026410", "X05040181", "X04201005", "X12670111", "X08100903",
"X01013315", "X01027205", "X12650101"
)
# 2. Preparar la matriz
matriz <- replace(data, is.na(data), 0)
matriz[matriz > 10] <- 0
matriz_dense <- as.matrix(matriz)
matriz_sparse <- as(Matrix(matriz_dense, sparse = TRUE), "dgCMatrix")
# 3. Entrenar modelo ALS
modelo_ALS <- WRMF$new(rank = 30, lambda = 0.1, feedback = "implicit")
modelo_ALS$fit_transform(matriz_sparse)
# 4. Recomendaciones para todos los clientes
id_usuarios <- 1:nrow(matriz)  # Todos los clientes
# 5. Predecir top 50 productos por cliente
predicciones <- modelo_ALS$predict(matriz_sparse[id_usuarios, , drop = FALSE], k = 1)
# 6. Filtrar predicciones solo a productos en oferta
cols_oferta <- which(colnames(matriz) %in% productos_en_oferta)
filtrar_oferta <- function(indices, cols_oferta) {
inter <- intersect(indices, cols_oferta)
if (length(inter) == 0) return(NA)
return(inter[1])
}
recomendaciones_filtradas <- sapply(predicciones, filtrar_oferta, cols_oferta = cols_oferta)
productos_recomendados <- colnames(matriz)[recomendaciones_filtradas]
# 7. Fallback: sorteo ponderado por popularidad
popularidad <- colSums(matriz_sparse)[productos_en_oferta]
set.seed(123)
fallbacks <- sample(
productos_en_oferta,
sum(is.na(recomendaciones_filtradas)),
replace = TRUE,
prob = popularidad
)
# Convertir a nombres de producto
productos_recomendados <- colnames(matriz)[recomendaciones_filtradas]
productos_recomendados[is.na(productos_recomendados)] <- fallbacks
# 8. Construir resultado final
resultado <- data.frame(
cliente = rownames(matriz),
producto_recomendado = productos_recomendados
)
# Limpieza de formatos
resultado$producto_recomendado <- as.character(resultado$producto_recomendado)
productos$cod_est <- as.character(productos$cod_est)
resultado$producto_recomendado <- sub("^X", "", resultado$producto_recomendado)
productos$cod_est <- sub("^X", "", productos$cod_est)
# Merge para obtener descripción del producto
resultado_final <- merge(resultado,
productos,
by.x = "producto_recomendado",
by.y = "cod_est",
all.x = TRUE)
# Selección de columnas finales
resultado_final <- resultado_final[, c("cliente", "producto_recomendado", "descripcion")]
# Ver resumen de recomendaciones
ct <- resultado_final %>%
group_by(descripcion) %>%
count()
# Mostrar tabla resumen
print(ct)
View(ct)
# Cargar librerías necesarias
library(recommenderlab)
library(rsparse)
library(Matrix)
library(dplyr)
# 1. Cargar datos
data <- readRDS("matriz.RDS")
objetivos <- readRDS("objetivos.RDS")
clientes_objetivo <- objetivos$objetivo2$obj
productos <- readRDS("maestroestr.RDS")
#  Vector con los códigos de los 20 productos en oferta (reemplaza con los reales si hace falta)
productos_en_oferta <- c("X12650103", "X01027405", "X05030101", "X05030102", "X01012310",
"X11040303", "X08230125", "X01201505", "X05040180", "X01201005", "X09070103",
"X04200505", "X01026410", "X05040181", "X04201005", "X12670111", "X08100903",
"X01013315", "X01027205", "X12650101"
)
# 2. Preparar la matriz
matriz <- replace(data, is.na(data), 0)
matriz[matriz > 10] <- 0
matriz_dense <- as.matrix(matriz)
matriz_sparse <- as(Matrix(matriz_dense, sparse = TRUE), "dgCMatrix")
# 3. Entrenar modelo ALS
modelo_ALS <- WRMF$new(rank = 30, lambda = 0.1, feedback = "implicit")
modelo_ALS$fit_transform(matriz_sparse)
# 4. Recomendaciones para todos los clientes
id_usuarios <- 1:nrow(matriz)  # Todos los clientes
# 5. Predecir top 50 productos por cliente
predicciones <- modelo_ALS$predict(matriz_sparse[id_usuarios, , drop = FALSE], k = 1)
# 6. Filtrar predicciones solo a productos en oferta
cols_oferta <- which(colnames(matriz) %in% productos_en_oferta)
filtrar_oferta <- function(indices, cols_oferta) {
inter <- intersect(indices, cols_oferta)
if (length(inter) == 0) return(NA)
return(inter[1])
}
recomendaciones_filtradas <- sapply(predicciones, filtrar_oferta, cols_oferta = cols_oferta)
productos_recomendados <- colnames(matriz)[recomendaciones_filtradas]
# 7. Fallback: sorteo ponderado por popularidad
popularidad <- colSums(matriz_sparse)[productos_en_oferta]
set.seed(123)
fallbacks <- sample(
productos_en_oferta,
sum(is.na(recomendaciones_filtradas)),
replace = TRUE,
prob = popularidad
)
# Convertir a nombres de producto
productos_recomendados <- colnames(matriz)[recomendaciones_filtradas]
productos_recomendados[is.na(productos_recomendados)] <- fallbacks
# 8. Construir resultado final
resultado <- data.frame(
cliente = rownames(matriz),
producto_recomendado = productos_recomendados
)
# Limpieza de formatos
resultado$producto_recomendado <- as.character(resultado$producto_recomendado)
productos$cod_est <- as.character(productos$cod_est)
resultado$producto_recomendado <- sub("^X", "", resultado$producto_recomendado)
productos$cod_est <- sub("^X", "", productos$cod_est)
# Merge para obtener descripción del producto
resultado_final <- merge(resultado,
productos,
by.x = "producto_recomendado",
by.y = "cod_est",
all.x = TRUE)
# Selección de columnas finales
resultado_final <- resultado_final[, c("cliente", "producto_recomendado", "descripcion")]
# Ver resumen de recomendaciones
ct <- resultado_final %>%
group_by(descripcion) %>%
count()
# Mostrar tabla resumen
print(ct)
clientes_objetivo <- objetivos$objetivo2$obj
clientes_objetivo <- objetivos$objetivo2$obj
clientes_objetivo
# Mostrar tabla resumen
print(ct)
clientes_objetivo <- objetivos$objetivo2$obj
clientes_objetivo
clientes_objetivo <- objetivos$objetivo3$obj
clientes_objetivo
View(ct)
clientes_objetivo <- objetivos$objetivo3$obj
clientes_objetivo
df=read.csv("C:/Users/jonba/Downloads/ds_salaries_def.csv")
library(dplyr)
library(tidyr)
library(shiny)
library(ggplot2)
library(plotly)
library(DT)
options(scipen=999)
df$remote_ratio=as.factor(df$remote_ratio)
df$experience_level=as.factor(df$experience_level)
ui <- fluidPage(
titlePanel("Anàlisis de Salarios y Perfiles en Ciencia de Datos"),
sidebarLayout(
sidebarPanel(
sliderInput('año', 'Selecciona el periodo temporal:', min=min(df$work_year), max=max(df$work_year), value=c(2020,2023), step=1),
checkboxGroupInput('tipo', 'Selecciona el tipo de empleo:', choices=unique(df$employment_type), selected=unique(df$employment_type)),
radioButtons('exp', 'Selecciona el nivel de experiencia:', choices =levels(df$experience_level), selected = 'EN'),
actionButton('calcular', 'calcular')
),
mainPanel(
tabsetPanel(
tabPanel('boxplot', plotlyOutput("G1")),
tabPanel('Tabla de Salarios', DTOutput('G2')),
tabPanel('Histograma', plotOutput('G3'))
)
)
)
)
server <- function(input, output, session){
tabla <- eventReactive(input$calcular, {
filter(df,
work_year >= input$año[1] &
work_year <= input$año[2] &
employment_type %in% input$tipo &
experience_level == input$exp)
})
output$G1 <- renderPlotly({
plot_ly(tabla(), y=~salary_in_usd, x= ~remote_ratio, color=~remote_ratio, type = "box")
})
output$G2 <- renderDT({
select(tabla(), c('work_year', 'job_title', 'salary_in_usd'))
})
output$G3 <- renderPlot({
ggplot(tabla(), aes(salary_in_usd)) +
geom_histogram(alpha=0.6, color='red', fill="red")
})
}
shinyApp(ui = ui,server = server)
